{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZM7mj7USxoj"
      },
      "source": [
        "**Unet architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vx_s-1tTYBU",
        "outputId": "81c0aed2-f44b-4af9-8972-a0bc3f2321f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzPiBGVWSwl0",
        "outputId": "85345b1d-84a3-4e91-f968-37c9dcbd975b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 512, 512, 64)         640       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 512, 512, 64)         256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 512, 512, 64)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 512, 512, 64)         36928     ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 512, 512, 64)         256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 512, 512, 64)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 256, 256, 64)         0         ['activation_1[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 256, 256, 128)        73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 256, 256, 128)        512       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 256, 256, 128)        0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 256, 256, 128)        147584    ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 256, 256, 128)        512       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 256, 256, 128)        0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 128, 128, 128)        0         ['activation_3[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 128, 128, 256)        295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 128, 128, 256)        1024      ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 128, 128, 256)        0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 128, 128, 256)        590080    ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 128, 128, 256)        1024      ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 128, 128, 256)        0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 64, 64, 256)          0         ['activation_5[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 64, 64, 512)          2048      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 64, 64, 512)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 64, 64, 512)          2359808   ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 64, 64, 512)          2048      ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 64, 64, 512)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 32, 32, 512)          0         ['activation_7[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 32, 32, 1024)         4096      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 32, 32, 1024)         0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 1024)         9438208   ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 32, 32, 1024)         4096      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 32, 32, 1024)         0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 64, 64, 512)          2097664   ['activation_9[0][0]']        \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 64, 64, 1024)         0         ['conv2d_transpose[0][0]',    \n",
            "                                                                     'activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 64, 64, 512)          4719104   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 64, 64, 512)          2048      ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 64, 64, 512)          2359808   ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 64, 64, 512)          2048      ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 128, 128, 256)        524544    ['activation_11[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 128, 128, 512)        0         ['conv2d_transpose_1[0][0]',  \n",
            " )                                                                   'activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 128, 128, 256)        1179904   ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 128, 128, 256)        1024      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 128, 128, 256)        590080    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 128, 128, 256)        1024      ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 256, 256, 128)        131200    ['activation_13[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 256, 256, 256)        0         ['conv2d_transpose_2[0][0]',  \n",
            " )                                                                   'activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 256, 256, 128)        295040    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 256, 256, 128)        512       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 256, 256, 128)        147584    ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 256, 256, 128)        512       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 512, 512, 64)         32832     ['activation_15[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 512, 512, 128)        0         ['conv2d_transpose_3[0][0]',  \n",
            " )                                                                   'activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 512, 512, 64)         73792     ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 512, 512, 64)         256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 512, 512, 64)         36928     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 512, 512, 64)         256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 512, 512, 9)          585       ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31054665 (118.46 MB)\n",
            "Trainable params: 31042889 (118.42 MB)\n",
            "Non-trainable params: 11776 (46.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape, num_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "\n",
        "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (512, 512, 1)\n",
        "    model = build_unet(input_shape,9)\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ3nayITSyVc"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwtoT0Iu0dNl",
        "outputId": "d642f524-55b1-4f3f-bab0-c1bc78e8747c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2210\n",
            "train:1768 , test: 442, valid :442\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 512, 512, 9), dtype=tf.uint8, name=None))>\n",
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 512, 512, 64)         640       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 512, 512, 64)         256       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 512, 512, 64)         36928     ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 512, 512, 64)         256       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 256, 256, 64)         0         ['activation_19[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 256, 256, 128)        73856     ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 256, 256, 128)        512       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 256, 256, 128)        147584    ['activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 256, 256, 128)        512       ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 128, 128, 128)        0         ['activation_21[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 128, 128, 256)        295168    ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 128, 128, 256)        1024      ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 128, 128, 256)        590080    ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 128, 128, 256)        1024      ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 64, 64, 256)          0         ['activation_23[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 64, 64, 512)          1180160   ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 64, 64, 512)          2048      ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 64, 64, 512)          2359808   ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 64, 64, 512)          2048      ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 32, 32, 512)          0         ['activation_25[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 32, 32, 1024)         4719616   ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 32, 32, 1024)         4096      ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 32, 32, 1024)         0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 32, 32, 1024)         9438208   ['activation_26[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 32, 32, 1024)         4096      ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 32, 32, 1024)         0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 64, 64, 512)          2097664   ['activation_27[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 64, 64, 1024)         0         ['conv2d_transpose_4[0][0]',  \n",
            " )                                                                   'activation_25[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 64, 64, 512)          4719104   ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 64, 64, 512)          2048      ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 64, 64, 512)          2359808   ['activation_28[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 64, 64, 512)          2048      ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 128, 128, 256)        524544    ['activation_29[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 128, 128, 512)        0         ['conv2d_transpose_5[0][0]',  \n",
            " )                                                                   'activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 128, 128, 256)        1179904   ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 128, 128, 256)        1024      ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 128, 128, 256)        590080    ['activation_30[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 128, 128, 256)        1024      ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2D  (None, 256, 256, 128)        131200    ['activation_31[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 256, 256, 256)        0         ['conv2d_transpose_6[0][0]',  \n",
            " )                                                                   'activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 256, 256, 128)        295040    ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 256, 256, 128)        512       ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 256, 256, 128)        147584    ['activation_32[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 256, 256, 128)        512       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2D  (None, 512, 512, 64)         32832     ['activation_33[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 512, 512, 128)        0         ['conv2d_transpose_7[0][0]',  \n",
            " )                                                                   'activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 512, 512, 64)         73792     ['concatenate_7[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 512, 512, 64)         256       ['conv2d_35[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 512, 512, 64)         36928     ['activation_34[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 512, 512, 64)         256       ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 512, 512, 9)          585       ['activation_35[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31054665 (118.46 MB)\n",
            "Trainable params: 31042889 (118.42 MB)\n",
            "Non-trainable params: 11776 (46.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.9253\n",
            "Epoch 1: val_loss improved from inf to 0.90284, saving model to results/model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r221/221 [==============================] - 537s 2s/step - loss: 0.9253 - val_loss: 0.9028 - lr: 1.0000e-04\n",
            "Epoch 2/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4103\n",
            "Epoch 2: val_loss improved from 0.90284 to 0.40393, saving model to results/model.h5\n",
            "221/221 [==============================] - 513s 2s/step - loss: 0.4103 - val_loss: 0.4039 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.2637\n",
            "Epoch 3: val_loss improved from 0.40393 to 0.25059, saving model to results/model.h5\n",
            "221/221 [==============================] - 490s 2s/step - loss: 0.2637 - val_loss: 0.2506 - lr: 1.0000e-04\n",
            "Epoch 4/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.1841\n",
            "Epoch 4: val_loss improved from 0.25059 to 0.15305, saving model to results/model.h5\n",
            "221/221 [==============================] - 491s 2s/step - loss: 0.1841 - val_loss: 0.1530 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.1340\n",
            "Epoch 5: val_loss did not improve from 0.15305\n",
            "221/221 [==============================] - 489s 2s/step - loss: 0.1340 - val_loss: 0.1739 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.1021\n",
            "Epoch 6: val_loss improved from 0.15305 to 0.09554, saving model to results/model.h5\n",
            "221/221 [==============================] - 490s 2s/step - loss: 0.1021 - val_loss: 0.0955 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0777\n",
            "Epoch 7: val_loss improved from 0.09554 to 0.08439, saving model to results/model.h5\n",
            "221/221 [==============================] - 490s 2s/step - loss: 0.0777 - val_loss: 0.0844 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0583\n",
            "Epoch 8: val_loss improved from 0.08439 to 0.05573, saving model to results/model.h5\n",
            "221/221 [==============================] - 515s 2s/step - loss: 0.0583 - val_loss: 0.0557 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0470\n",
            "Epoch 9: val_loss improved from 0.05573 to 0.05540, saving model to results/model.h5\n",
            "221/221 [==============================] - 492s 2s/step - loss: 0.0470 - val_loss: 0.0554 - lr: 1.0000e-04\n",
            "Epoch 10/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0370\n",
            "Epoch 10: val_loss improved from 0.05540 to 0.03086, saving model to results/model.h5\n",
            "221/221 [==============================] - 491s 2s/step - loss: 0.0370 - val_loss: 0.0309 - lr: 1.0000e-04\n",
            "Epoch 11/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0293\n",
            "Epoch 11: val_loss did not improve from 0.03086\n",
            "221/221 [==============================] - 489s 2s/step - loss: 0.0293 - val_loss: 0.0318 - lr: 1.0000e-04\n",
            "Epoch 12/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0259\n",
            "Epoch 12: val_loss did not improve from 0.03086\n",
            "221/221 [==============================] - 490s 2s/step - loss: 0.0259 - val_loss: 0.0397 - lr: 1.0000e-04\n",
            "Epoch 13/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0208\n",
            "Epoch 13: val_loss improved from 0.03086 to 0.01997, saving model to results/model.h5\n",
            "221/221 [==============================] - 515s 2s/step - loss: 0.0208 - val_loss: 0.0200 - lr: 1.0000e-04\n",
            "Epoch 14/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0174\n",
            "Epoch 14: val_loss improved from 0.01997 to 0.01894, saving model to results/model.h5\n",
            "221/221 [==============================] - 496s 2s/step - loss: 0.0174 - val_loss: 0.0189 - lr: 1.0000e-04\n",
            "Epoch 15/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0145\n",
            "Epoch 15: val_loss improved from 0.01894 to 0.01595, saving model to results/model.h5\n",
            "221/221 [==============================] - 492s 2s/step - loss: 0.0145 - val_loss: 0.0159 - lr: 1.0000e-04\n",
            "Epoch 16/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0198\n",
            "Epoch 16: val_loss did not improve from 0.01595\n",
            "221/221 [==============================] - 489s 2s/step - loss: 0.0198 - val_loss: 0.0208 - lr: 1.0000e-04\n",
            "Epoch 17/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0129\n",
            "Epoch 17: val_loss improved from 0.01595 to 0.01531, saving model to results/model.h5\n",
            "221/221 [==============================] - 489s 2s/step - loss: 0.0129 - val_loss: 0.0153 - lr: 1.0000e-04\n",
            "Epoch 18/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0109\n",
            "Epoch 18: val_loss improved from 0.01531 to 0.01285, saving model to results/model.h5\n",
            "221/221 [==============================] - 491s 2s/step - loss: 0.0109 - val_loss: 0.0128 - lr: 1.0000e-04\n",
            "Epoch 19/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0099\n",
            "Epoch 19: val_loss improved from 0.01285 to 0.01205, saving model to results/model.h5\n",
            "221/221 [==============================] - 489s 2s/step - loss: 0.0099 - val_loss: 0.0120 - lr: 1.0000e-04\n",
            "Epoch 20/20\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.0092\n",
            "Epoch 20: val_loss improved from 0.01205 to 0.01148, saving model to results/model.h5\n",
            "221/221 [==============================] - 514s 2s/step - loss: 0.0092 - val_loss: 0.0115 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "import scipy.io\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
        "from tensorflow.keras.optimizers import Adam as LegacyAdam\n",
        "\"\"\" Global parameters \"\"\"\n",
        "global IMG_H\n",
        "global IMG_W\n",
        "global NUM_CLASSES\n",
        "global CLASSES\n",
        "global COLORMAP\n",
        "\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "\n",
        "def load_dataset(path, split=0.2):\n",
        "  data = sorted(glob(os.path.join(path,\"*\")))\n",
        "  print(len(data))\n",
        "  split_size=int(split*len(data))\n",
        "  train, valid = train_test_split(data, test_size=split_size, random_state=42)\n",
        "  train, test = train_test_split(data, test_size=split_size, random_state=42)\n",
        "\n",
        "  return train, valid, test\n",
        "\n",
        "\n",
        "def read_image_label(x):\n",
        "  x = np.load(x)\n",
        "  img = x['image']\n",
        "  label = x['label']\n",
        "  img = np.expand_dims(img,axis = -1);\n",
        "  label = np.expand_dims(label,axis = -1);\n",
        "  assert img.shape == label.shape\n",
        "  \"\"\" Image processing \"\"\"\n",
        "  img = img.astype(np.float32)\n",
        "  \"\"\" label processing \"\"\"\n",
        "  output = []\n",
        "  for color in COLORMAP:\n",
        "    cmap = np.all(np.equal(label, color), axis=-1)\n",
        "    output.append(cmap)\n",
        "  output = np.stack(output, axis=-1)\n",
        "  output = output.astype(np.uint8)\n",
        "\n",
        "  return img,output\n",
        "\n",
        "\n",
        "def preprocess(x):\n",
        "    def f(x):\n",
        "        x = x.decode()\n",
        "        image, mask = read_image_label(x)\n",
        "        return image, mask\n",
        "\n",
        "    image, mask = tf.numpy_function(f,[x], [tf.float32, tf.uint8])\n",
        "    image.set_shape([512, 512, 1])\n",
        "    mask.set_shape([512, 512, 9])\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "def tf_dataset(x, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(x)\n",
        "    dataset = dataset.shuffle(buffer_size=1000)\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(2)\n",
        "    return dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Directory for storing files \"\"\"\n",
        "    create_dir(\"results\")\n",
        "\n",
        "    \"\"\" Hyperparameters \"\"\"\n",
        "    IMG_H = 512\n",
        "    IMG_W = 512\n",
        "    NUM_CLASSES = 9\n",
        "    input_shape = (IMG_H, IMG_W, 1)\n",
        "\n",
        "    batch_size = 6\n",
        "    lr = 1e-4\n",
        "    num_epochs = 20\n",
        "\n",
        "    model_path = os.path.join(\"results\", \"model.h5\")\n",
        "    csv_path = os.path.join(\"results\", \"data.csv\")\n",
        "\n",
        "    path = \"/content/drive/MyDrive/train_npz\"\n",
        "\n",
        "    train , valid , test = load_dataset(path)\n",
        "\n",
        "    mat_file = scipy.io.loadmat('MOS.mat')\n",
        "\n",
        "    COLORMAP = mat_file['colormap']\n",
        "\n",
        "    print(f\"train:{len(train)} , test: {len(test)}, valid :{len(valid)}\")\n",
        "\n",
        "    train_dataset = tf_dataset(train, batch=8)\n",
        "    valid_dataset = tf_dataset(valid, batch=8)\n",
        "\n",
        "    print(train_dataset);\n",
        "    \"\"\" Model \"\"\"\n",
        "\n",
        "    model = build_unet(input_shape, NUM_CLASSES)\n",
        "    # model.load_weights(model_path)\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.legacy.Adam(lr)\n",
        "    )\n",
        "    model.summary()\n",
        "\n",
        "    \"\"\" Training \"\"\"\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "        CSVLogger(csv_path, append=True),\n",
        "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
        "    ]\n",
        "\n",
        "    model.fit(train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=num_epochs,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Egf4aHVzEZ"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKFlE3TyV5yM",
        "outputId": "3e4231c7-dc3d-4ecb-d796-83e55d7dc9f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2210\n",
            "train:1768 , test: 442, valid :442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7cc1fc138ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7cc1fc13b640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 9)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c22b14f40b8b>\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m  }\n\u001b[1;32m    128\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{classes[j]:15s} = F1:{score[0][j]:10s} , jac :{score[1][j]:10s}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown format code 's' for object of type 'float'"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "\"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    union = np.sum(y_true) + np.sum(y_pred)\n",
        "    return 2.0 * intersection / union\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_dataset(path, split=0.2):\n",
        "  data = sorted(glob(os.path.join(path,\"*\")))\n",
        "  print(len(data))\n",
        "  split_size=int(split*len(data))\n",
        "  train, valid = train_test_split(data, test_size=split_size, random_state=42)\n",
        "  train, test = train_test_split(data, test_size=split_size, random_state=42)\n",
        "\n",
        "  return train, valid, test\n",
        "\n",
        "def predict(data):\n",
        "  x = np.load(data)\n",
        "  image = x['image']\n",
        "  label = x['label']\n",
        "\n",
        "  # prediction\n",
        "  img = np.expand_dims(image, axis=0)\n",
        "  \"\"\" Model \"\"\"\n",
        "  model_path = \"/content/drive/MyDrive/MOS_model_50.h5\"\n",
        "  model = tf.keras.models.load_model(model_path)\n",
        "  \"\"\" Prediction \"\"\"\n",
        "  pred = model.predict(img, verbose=0)[0]\n",
        "  pred = np.argmax(pred, axis=-1)\n",
        "  pred = pred.astype(np.float32)\n",
        "\n",
        "  cmap = {\n",
        "    0.0 : [0,0,0],\n",
        "    0.1 : [255,0,0],\n",
        "    0.2 : [255,255,1],\n",
        "    0.3 : [0,0,255],\n",
        "    0.4 : [0,255,1],\n",
        "    0.5 : [255,0,255],\n",
        "    0.6 : [0,255,255],\n",
        "    0.7 : [244,208,63],\n",
        "    0.8 : [234,240,241]\n",
        "  }\n",
        "\n",
        "  colored_label = np.array([[cmap[pixel/10] for pixel in row] for row in label])\n",
        "  colored_Prediction = np.array([[cmap[pixel/10] for pixel in row] for row in pred ])\n",
        "\n",
        "  #  rgb , rotate  & flip\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "  image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
        "  image = cv2.flip(image, 1)\n",
        "  colored_label = cv2.rotate(colored_label, cv2.ROTATE_90_CLOCKWISE)\n",
        "  colored_label = cv2.flip(colored_label, 1)\n",
        "  colored_Prediction = cv2.rotate(colored_Prediction, cv2.ROTATE_90_CLOCKWISE)\n",
        "  colored_Prediction = cv2.flip(colored_Prediction, 1)\n",
        "\n",
        "  image = image*255\n",
        "  alpha = 0.5\n",
        "  image1 = alpha * image + (1 - alpha) * colored_label\n",
        "  image2 = alpha * image + (1 - alpha) * colored_Prediction\n",
        "  # cv2_imshow(image)\n",
        "  # cv2_imshow(image1)\n",
        "  # cv2_imshow(image2)\n",
        "\n",
        "  return image, image1, image2\n",
        "  # print(f\"Image = {image.shape}\")\n",
        "  # print(f\"Image1 = {image1.shape}\")\n",
        "  # print(f\"Image2 = {image2.shape}\")\n",
        "\n",
        "create_dir(\"pred_imgs_view\")\n",
        "path = \"/content/drive/MyDrive/train_npz\"\n",
        "train , valid , test = load_dataset(path)\n",
        "print(f\"train:{len(train)} , test: {len(test)}, valid :{len(valid)}\")\n",
        "\n",
        "# reading data of size (512 X 512) grayscale both image and label\n",
        "data_test = test\n",
        "SCORE = []\n",
        "f = 0;\n",
        "for data in test[:200] :\n",
        "  img,g_truth,prediction = predict(data);\n",
        "  res = np.concatenate([img,g_truth,prediction])\n",
        "  cv2.imwrite(f\"/content/pred_imgs_view/{f}.png\",res)\n",
        "  f = f+1\n",
        "\n",
        "  g_truth    = g_truth.flatten().astype(np.int32)\n",
        "  prediction = prediction.flatten().astype(np.int32)\n",
        "\n",
        "  labels = [i for i in range(9)]\n",
        "\n",
        "  f1_value = f1_score(g_truth, prediction, labels=labels, average=None, zero_division=0)\n",
        "  jac_value = jaccard_score(g_truth, prediction, labels=labels, average=None, zero_division=0)\n",
        "  SCORE.append([f1_value, jac_value])\n",
        "\n",
        "\n",
        "score = np.array(SCORE)\n",
        "score = np.mean(score, axis=0)\n",
        "print(score.shape)\n",
        "\n",
        "classes= {\n",
        "    0:\"Background\",\n",
        "    1:\"aorta\",\n",
        "    2:\"right kidney\",\n",
        "    3:\"left kidney\",\n",
        "    4:\"gallbladder\",\n",
        "    5:\"liver\",\n",
        "    6:\"pancreas\",\n",
        "    7:\"spleen\",\n",
        "    8:\"stomach\"\n",
        " }\n",
        "for j in range(9):\n",
        "  print(f\"{classes[j]:15s} = F1:{score[0][j]:10s} , jac :{score[1][j]:10s}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trIfIxVwABbS",
        "outputId": "ce109d99-13b0-4081-f284-33eb7eecc731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 9)\n",
            "Background      = DCS: 0.9999906848112584 , jac : 0.9999813721141281\n",
            "aorta           = DCS: 0.9997785110396673 , jac : 0.9995586073890874\n",
            "right kidney    = DCS: 0.9997983408369022 , jac : 0.999599025042774\n",
            "left kidney     = DCS: 0.9998478711322994 , jac : 0.999696504122554\n",
            "gallbladder     = DCS: 0.9998174552032542 , jac : 0.9996361839732293\n",
            "liver           = DCS: 0.9998324002512908 , jac : 0.9996654838556134\n",
            "pancreas        = DCS: 0.9998563455011684 , jac : 0.9997131509614731\n",
            "spleen          = DCS: 0.9998353360164097 , jac : 0.9996712979907109\n",
            "stomach         = DCS: 0.9998117677356336 , jac : 0.9996242526717996\n"
          ]
        }
      ],
      "source": [
        "print(score.shape)\n",
        "classes= {\n",
        "    0:\"Background\",\n",
        "    1:\"aorta\",\n",
        "    2:\"right kidney\",\n",
        "    3:\"left kidney\",\n",
        "    4:\"gallbladder\",\n",
        "    5:\"liver\",\n",
        "    6:\"pancreas\",\n",
        "    7:\"spleen\",\n",
        "    8:\"stomach\"\n",
        " }\n",
        "for j in range(9):\n",
        "  print(f\"{classes[j]:15s} = DCS: {score[0][j]} , jac : {score[1][j]}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}